{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3UYjP--vJp6y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UYjP--vJp6y",
    "outputId": "53e975d0-d034-4434-e2f9-d63aab916aef"
   },
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boK3ljQYLYvX",
   "metadata": {
    "id": "boK3ljQYLYvX"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubpKjURSLZOt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubpKjURSLZOt",
    "outputId": "c651a1ce-3754-4057-cb8a-310e460a9b8e"
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T2YkMszWL64I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2YkMszWL64I",
    "outputId": "4efa0211-0169-4939-c15d-062978119685"
   },
   "outputs": [],
   "source": [
    "!unzip amazon-fine-food-reviews.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cjSe1KCrYQ7Y",
   "metadata": {
    "id": "cjSe1KCrYQ7Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.sparse import csr_matrix\n",
    "from transformers import pipeline, RobertaTokenizerFast\n",
    "\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkj_LJw0EC-K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkj_LJw0EC-K",
    "outputId": "36ccde0b-5989-4791-8f91-120d8313f0bb"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "\n",
    "# Convert scores to labels\n",
    "def create_label(score):\n",
    "    if score >= 4:\n",
    "        return \"positive\"\n",
    "    elif score < 4:\n",
    "        return \"negative\"\n",
    "\n",
    "df[\"label\"] = df[\"Score\"].apply(create_label)\n",
    "\n",
    "# Keep only positive and negative labels\n",
    "df = df[df[\"label\"].isin([\"positive\", \"negative\"])]\n",
    "\n",
    "# Undersample the positive reviews\n",
    "positive_count = df[df[\"label\"] == \"positive\"].shape[0]\n",
    "negative_count = df[df[\"label\"] == \"negative\"].shape[0]\n",
    "if positive_count > negative_count:\n",
    "    df = pd.concat([\n",
    "        df[df[\"label\"] == \"positive\"].sample(negative_count, random_state=42),\n",
    "        df[df[\"label\"] == \"negative\"]\n",
    "    ], axis=0)\n",
    "else:\n",
    "    df = pd.concat([\n",
    "        df[df[\"label\"] == \"positive\"],\n",
    "        df[df[\"label\"] == \"negative\"].sample(positive_count, random_state=42)\n",
    "    ], axis=0)\n",
    "\n",
    "# Select a random subset of samples between 1000 and 10000\n",
    "num_samples = np.random.randint(1000, 10000)\n",
    "df = df.sample(num_samples, random_state=42)\n",
    "\n",
    "# Keep the nine most frequent labels and combine the less popular labels into an \"Other\" label\n",
    "top_labels = df[\"label\"].value_counts().nlargest(9).index\n",
    "df.loc[~df[\"label\"].isin(top_labels), \"label\"] = \"Other\"\n",
    "df.shape[0]\n",
    "\n",
    "# Split the dataset into training, validation, and test sets with a 60/20/20% split\n",
    "train_val_test_split = [0.6, 0.2, 0.2]\n",
    "num_samples = len(df)\n",
    "num_train_samples = int(train_val_test_split[0] * num_samples)\n",
    "num_val_samples = int(train_val_test_split[1] * num_samples)\n",
    "\n",
    "df = df.sample(frac=1, random_state=42) # Shuffle the dataset\n",
    "train_df = df[:num_train_samples]\n",
    "val_df = df[num_train_samples:num_train_samples+num_val_samples]\n",
    "test_df = df[num_train_samples+num_val_samples:]\n",
    "\n",
    "# Table with label counts for each split of the dataset\n",
    "label_counts = pd.DataFrame({\n",
    "    \"train\": train_df[\"label\"].value_counts(),\n",
    "    \"val\": val_df[\"label\"].value_counts(),\n",
    "    \"test\": test_df[\"label\"].value_counts()\n",
    "}).transpose()\n",
    "\n",
    "print(label_counts)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291e1c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d291e1c6",
    "outputId": "586a0235-6065-49f6-897a-d1b2a911f5d4"
   },
   "outputs": [],
   "source": [
    "# Step 0: Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "X_val = vectorizer.transform(val_df['Text'])\n",
    "X_test = vectorizer.transform(test_df['Text'])\n",
    "X_all = vstack([X_train, X_val, X_test])\n",
    "\n",
    "# Step 1: Pick k random centroids\n",
    "k = 5\n",
    "np.random.seed(42)\n",
    "X_train_dense = X_train.toarray()\n",
    "centroids = X_train_dense[np.random.choice(X_train_dense.shape[0], k, replace=False), :]\n",
    "\n",
    "\n",
    "# Step 2 and 3: Assign vectors to their closest centroid and recalculate centroids\n",
    "for i in range(10):  # repeat steps 2 and 3 for 10 iterations\n",
    "    # calculate distance between each vector and each centroid\n",
    "    dist = np.array([np.linalg.norm(X_all.toarray() - centroid, axis=1) for centroid in centroids]).T\n",
    "    # assign each vector to the closest centroid\n",
    "    cluster_labels = np.argmin(dist, axis=1)\n",
    "    # calculate new centroids based on the mean of vectors in each cluster\n",
    "    new_centroids = np.zeros_like(centroids)\n",
    "    for j in range(k):\n",
    "        cluster_samples = X_all[cluster_labels == j].toarray()\n",
    "        if cluster_samples.shape[0] > 0:\n",
    "            cluster_samples = X_all[cluster_labels == j].toarray()\n",
    "            new_centroids[j] = cluster_samples.mean(axis=0)\n",
    "        elif cluster_samples.shape[0] == 0:\n",
    "            new_centroids[j] = centroids[j]\n",
    "        else:\n",
    "            new_centroids[j] = centroids[j]\n",
    "\n",
    "        \n",
    "    # check if clusters have converged\n",
    "    if np.allclose(new_centroids, centroids):\n",
    "        break\n",
    "    centroids = new_centroids\n",
    "    \n",
    "# Assign cluster labels to each document\n",
    "train_cluster_labels = np.argmin(np.array([np.linalg.norm(X_train - centroid, axis=1) for centroid in centroids]).T, axis=1)\n",
    "val_cluster_labels = np.argmin(np.array([np.linalg.norm(X_val - centroid, axis=1) for centroid in centroids]).T, axis=1)\n",
    "test_cluster_labels = np.argmin(np.array([np.linalg.norm(X_test - centroid, axis=1) for centroid in centroids]).T, axis=1)\n",
    "\n",
    "# For each cluster, print out some example documents and the top 5 tokens in the corresponding centroid\n",
    "for cluster_num in range(2):\n",
    "    print(f\"Cluster {cluster_num}:\")\n",
    "    train_examples = train_df.iloc[train_cluster_labels == cluster_num].sample(5)[\"Text\"].tolist()\n",
    "    val_examples = val_df.iloc[val_cluster_labels == cluster_num].sample(5)[\"Text\"].tolist()\n",
    "    test_examples = test_df.iloc[test_cluster_labels == cluster_num].sample(5)[\"Text\"].tolist()\n",
    "    print(f\"Training examples:\\n{train_examples}\\n\")\n",
    "    print(f\"Validation examples:\\n{val_examples}\\n\")\n",
    "    print(f\"Test examples:\\n{test_examples}\\n\")\n",
    "    top_tokens = np.array(vectorizer.get_feature_names_out())[np.argsort(-centroids[cluster_num])[:5]]\n",
    "    print(f\"Top 5 tokens in centroid: {top_tokens}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86132c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86132c16",
    "outputId": "941681a0-67bd-4169-c863-720e7aa59fe5"
   },
   "outputs": [],
   "source": [
    "# Step 0: Vectorize text\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_df['label'])\n",
    "X_val = vectorizer.transform(val_df['label'])\n",
    "X_test = vectorizer.transform(test_df['label'])\n",
    "X_all = vstack([X_train, X_val, X_test])\n",
    "\n",
    "# Step 1: Train KMeans model\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X_all)\n",
    "\n",
    "# Step 2: Get predicted cluster labels for test data\n",
    "y_kmeans = kmeans.predict(X_test)\n",
    "\n",
    "\n",
    "# Step 3: Construct confusion matrix\n",
    "label_map = {label: i for i, label in enumerate(train_df['label'].unique())}\n",
    "y_true = test_df['label'].map(label_map)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_kmeans)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bV-3qSn75XXQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "bV-3qSn75XXQ",
    "outputId": "55dbadb8-5ecd-4dd7-96ac-d89ee2be1485"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xticklabels=train_df['label'].unique(), \n",
    "       yticklabels=train_df['label'].unique(),\n",
    "       xlabel='Predicted label',\n",
    "       ylabel='True label')\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "fmt = '.2f'\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe0a5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8afe0a5b",
    "outputId": "556208e5-6e54-4f9c-9d71-07c9cd4ef491"
   },
   "outputs": [],
   "source": [
    "# Define the feature representations\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training set with each feature representation\n",
    "X_train_cv = cv.fit_transform(train_df[\"Text\"])\n",
    "X_train_tfidf = tfidf.fit_transform(train_df[\"Text\"])\n",
    "\n",
    "# Transform the validation set with each feature representation\n",
    "X_val_cv = cv.transform(val_df[\"Text\"])\n",
    "X_val_tfidf = tfidf.transform(val_df[\"Text\"])\n",
    "\n",
    "# Define the Dummy Classifiers\n",
    "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "dc_stratified = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "\n",
    "# Define the Logistic Regression classifiers\n",
    "lr_cv = LogisticRegression(max_iter=10000)\n",
    "lr_tfidf = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Fit the classifiers on the training set\n",
    "dc_most_frequent.fit(X_train_cv, train_df[\"label\"])\n",
    "dc_stratified.fit(X_train_cv, train_df[\"label\"])\n",
    "\n",
    "lr_cv.fit(X_train_cv, train_df[\"label\"])\n",
    "lr_tfidf.fit(X_train_tfidf, train_df[\"label\"])\n",
    "\n",
    "# Evaluate the classifiers on the validation set\n",
    "y_val_true = val_df[\"label\"]\n",
    "\n",
    "y_val_pred_dc_most_frequent = dc_most_frequent.predict(X_val_cv)\n",
    "y_val_pred_dc_stratified = dc_stratified.predict(X_val_cv)\n",
    "\n",
    "y_val_pred_lr_cv = lr_cv.predict(X_val_cv)\n",
    "y_val_pred_lr_tfidf = lr_tfidf.predict(X_val_tfidf)\n",
    "\n",
    "acc_dc_most_frequent = accuracy_score(y_val_true, y_val_pred_dc_most_frequent)\n",
    "acc_dc_stratified = accuracy_score(y_val_true, y_val_pred_dc_stratified)\n",
    "acc_lr_cv = accuracy_score(y_val_true, y_val_pred_lr_cv)\n",
    "acc_lr_tfidf = accuracy_score(y_val_true, y_val_pred_lr_tfidf)\n",
    "\n",
    "print(\"Dummy Classifier with strategy='most_frequent' accuracy:\", acc_dc_most_frequent)\n",
    "print(\"Dummy Classifier with strategy='stratified' accuracy:\", acc_dc_stratified)\n",
    "print(\"LogisticRegression with One-hot vectorization accuracy:\", acc_lr_cv)\n",
    "print(\"LogisticRegression with TF-IDF vectorization accuracy:\", acc_lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3a5da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17a3a5da",
    "outputId": "6ecde6d4-1b42-4e9a-9137-e96cd988b3ba"
   },
   "outputs": [],
   "source": [
    "# Define the classifiers\n",
    "dummy_clf_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "logreg_clf_onehot = LogisticRegression(max_iter=1000)\n",
    "logreg_clf_tfidf = LogisticRegression(max_iter=1000)\n",
    "svm_clf_onehot = SVC()\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer_onehot = CountVectorizer(binary=True)\n",
    "X_train_onehot = vectorizer_onehot.fit_transform(train_df[\"Text\"])\n",
    "X_val_onehot = vectorizer_onehot.transform(val_df[\"Text\"])\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(train_df[\"Text\"])\n",
    "X_val_tfidf = vectorizer_tfidf.transform(val_df[\"Text\"])\n",
    "\n",
    "# Fit the classifiers\n",
    "dummy_clf_frequent.fit(X_train_onehot, train_df[\"label\"])\n",
    "dummy_clf_stratified.fit(X_train_onehot, train_df[\"label\"])\n",
    "logreg_clf_onehot.fit(X_train_onehot, train_df[\"label\"])\n",
    "logreg_clf_tfidf.fit(X_train_tfidf, train_df[\"label\"])\n",
    "svm_clf_onehot.fit(X_train_onehot, train_df[\"label\"])\n",
    "\n",
    "# Evaluate the classifiers\n",
    "def evaluate_clf(clf, X, y_true):\n",
    "    y_pred = clf.predict(X)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return acc, precision, recall, f1\n",
    "\n",
    "dummy_frequent_acc, dummy_frequent_prec, dummy_frequent_rec, dummy_frequent_f1 = evaluate_clf(dummy_clf_frequent, X_val_onehot, val_df[\"label\"])\n",
    "dummy_stratified_acc, dummy_stratified_prec, dummy_stratified_rec, dummy_stratified_f1 = evaluate_clf(dummy_clf_stratified, X_val_onehot, val_df[\"label\"])\n",
    "logreg_onehot_acc, logreg_onehot_prec, logreg_onehot_rec, logreg_onehot_f1 = evaluate_clf(logreg_clf_onehot, X_val_onehot, val_df[\"label\"])\n",
    "logreg_tfidf_acc, logreg_tfidf_prec, logreg_tfidf_rec, logreg_tfidf_f1 = evaluate_clf(logreg_clf_tfidf, X_val_tfidf, val_df[\"label\"])\n",
    "svm_onehot_acc, svm_onehot_prec, svm_onehot_rec, svm_onehot_f1 = evaluate_clf(svm_clf_onehot, X_val_onehot, val_df[\"label\"])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Dummy Classifier with strategy='most_frequent' accuracy: {:.4f}\".format(dummy_frequent_acc))\n",
    "print(\"Dummy Classifier with strategy='most_frequent' macro-averaged precision: {:.4f}\".format(dummy_frequent_prec))\n",
    "print(\"Dummy Classifier with strategy='most_frequent' macro-averaged recall: {:.4f}\".format(dummy_frequent_rec))\n",
    "print(\"Dummy Classifier with strategy='most_frequent' macro-averaged F1: {:.4f}\".format(dummy_frequent_f1))\n",
    "print()\n",
    "print(\"Dummy Classifier with strategy='stratified' accuracy: {:.4f}\".format(dummy_stratified_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NaeLdKaVQbXb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "NaeLdKaVQbXb",
    "outputId": "a8313205-b0f6-40db-e2d6-1712b59e83c8"
   },
   "outputs": [],
   "source": [
    "# Set the F1 scores\n",
    "f1_scores = [dummy_frequent_f1, dummy_stratified_f1, logreg_onehot_f1, logreg_tfidf_f1, svm_onehot_f1]\n",
    "\n",
    "# Set the x labels\n",
    "x_labels = ['Dummy Classifier\\n(strategy=\\'most_frequent\\')', 'Dummy Classifier\\n(strategy=\\'stratified\\')', 'Logistic Regression\\n(with one-hot encoding)', 'Logistic Regression\\n(with TF-IDF encoding)', 'SVM\\n(with one-hot encoding)']\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(x_labels, f1_scores, color=['#1f77b0', '#1f77b4', '#1f77b9', '#1f77b7', '#1f77b6'])\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.xticks(fontsize=12, rotation=30, ha='right')\n",
    "plt.title('Comparison of F1 scores of classifiers', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gcg01o2hasGa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcg01o2hasGa",
    "outputId": "6f4fda38-c21e-46af-d100-a0cf0b9473bd"
   },
   "outputs": [],
   "source": [
    "#comparing classifiers part b (Naive Bayes algorithm)\n",
    "# Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "df['text'] = df['Text'].apply(preprocess)\n",
    "df['rating'] = df['Score'].apply(lambda x: 1 if x > 3 else 0)  # Convert 5-star rating to binary label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('F1 Score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f027b4",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "18f027b4"
   },
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(df['Text'], df['Score'], test_size=0.2, random_state=42, stratify=df['Score'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42, stratify=y_trainval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ijbRU7G6qtU",
   "metadata": {
    "id": "5ijbRU7G6qtU"
   },
   "outputs": [],
   "source": [
    "# Select a random subset of samples between 1000 and 10000\n",
    "num_samples = np.random.randint(1000, 10000)\n",
    "df = df.sample(num_samples, random_state=42)\n",
    "\n",
    "# Convert the 'Text' column to string type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Preprocess the text data\n",
    "df['Text'] = df['Text'].str.lower()  # Convert text to lowercase\n",
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]', '', regex=True)  # Remove punctuation\n",
    "df['Text'] = df['Text'].str.replace('\\d+', '', regex=True)  # Remove digits\n",
    "df['Text'] = df['Text'].str.strip()  # Remove leading and trailing whitespaces\n",
    "\n",
    "# Reduce the number of rows\n",
    "df = df.head(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VULi-a8t635U",
   "metadata": {
    "id": "VULi-a8t635U"
   },
   "outputs": [],
   "source": [
    "X_trainval, X_test, y_trainval, y_test = train_test_split(df['Text'], df['Score'], test_size=0.2, random_state=42, stratify=df['Score'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42, stratify=y_trainval)\n",
    "\n",
    "lr_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'tfidf__sublinear_tf': [True, False],\n",
    "    'tfidf__max_features': [None, 10000, 20000, 30000, 40000, 50000],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'lr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HBWkTUrJ67dQ",
   "metadata": {
    "id": "HBWkTUrJ67dQ"
   },
   "outputs": [],
   "source": [
    "grid_search_lr_tfidf = GridSearchCV(lr_tfidf, parameters, cv=5, n_jobs=-1, scoring='accuracy', \n",
    "                                     pre_dispatch='2*n_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kS_KE-cNxgrr",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kS_KE-cNxgrr",
    "outputId": "6d6e8671-d671-4495-88f7-0e22c617b465"
   },
   "outputs": [],
   "source": [
    "# Fit the model on sparse matrices\n",
    "print(\"test run\")\n",
    "grid_search_lr_tfidf.fit(X_trainval, y_trainval)\n",
    "\n",
    "# Print the best parameters and the corresponding accuracy score\n",
    "print(\"Best parameters: \", grid_search_lr_tfidf.best_params_)\n",
    "print(\"Best accuracy score: \", grid_search_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JUNiin0od6er",
   "metadata": {
    "id": "JUNiin0od6er"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # shuffle the dataset\n",
    "\n",
    "df = df[['Text', 'Score']].copy()\n",
    "df = df[df['Score'] != 3].reset_index(drop=True)  # remove neutral reviews\n",
    "df['Sentiment'] = df['Score'].apply(lambda x: 1 if x > 3 else 0)  # convert scores to binary sentiment\n",
    "\n",
    "df = df[:10000]  # reduce the dataset to 10,000 rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nV-2vIrdlIiY",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "nV-2vIrdlIiY",
    "outputId": "b57701a9-0b25-4837-937d-3843fc58175a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline, RobertaTokenizerFast\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('Reviews.csv')\n",
    "df = df.sample(frac=1).reset_index(drop=True)  # shuffle the dataset\n",
    "\n",
    "df = df[['Text', 'Score']]\n",
    "df = df[df['Score'] != 3]  # remove neutral reviews\n",
    "df['Sentiment'] = df['Score'].apply(lambda x: 1 if x > 3 else 0)  # convert scores to binary sentiment\n",
    "\n",
    "df = df[:10000]  # reduce the dataset to 10,000 rows\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract features with Roberta\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "feature_extractor = pipeline('feature-extraction', model='roberta-base', tokenizer=tokenizer)\n",
    "\n",
    "try:\n",
    "    X_train_features = [feature_extractor(text, max_length=128, padding=\"max_length\", truncation=True)[0][0] for text in X_train]\n",
    "    X_test_features = [feature_extractor(text, max_length=128, padding=\"max_length\", truncation=True)[0][0] for text in X_test]\n",
    "\n",
    "    # Train logistic regression classifier\n",
    "    clf = LogisticRegression(random_state=42)\n",
    "    clf.fit(X_train_features, y_train)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    y_pred = clf.predict(X_test_features)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spMQzayhd6lb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "spMQzayhd6lb",
    "outputId": "4d2eb020-5370-4be6-8fd9-0c357ffb0a32"
   },
   "outputs": [],
   "source": [
    "# Next, we'll use the HuggingFace pipeline to extract features from the text using the 'roberta-base' model and create a logistic regression classifier:\n",
    "# Extract features with Roberta\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "feature_extractor = pipeline('feature-extraction', model='roberta-base', tokenizer=tokenizer, padding=True, max_length=128)\n",
    "\n",
    "X_train_features = [feature_extractor(text, max_length=128)[0][0] for text in X_train]\n",
    "X_test_features = [feature_extractor(text, max_length=128)[0][0] for text in X_test]\n",
    "\n",
    "# Train logistic regression classifier\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(X_train_features, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred = clf.predict(X_test_features)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50kOG-WAd6oa",
   "metadata": {
    "id": "50kOG-WAd6oa"
   },
   "outputs": [],
   "source": [
    "# For part (b), we'll train an end-to-end classifier using the HuggingFace 'trainer' function:\n",
    "from transformers import RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.0,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=X_train,\n",
    "    eval_dataset=X_test\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on validation set\n",
    "predictions = trainer.predict(X_test)\n",
    "y_pred = predictions.predictions.argmax(-1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GMRO5HV-eMyg",
   "metadata": {
    "id": "GMRO5HV-eMyg"
   },
   "outputs": [],
   "source": [
    "# For part (c), we'll try three different sets of hyperparameters:\n",
    "# Hyperparameters for set 1\n",
    "learning_rate_1 = 5e-5\n",
    "num_epochs_1 = 2\n",
    "batch_size_1 = 32\n",
    "\n",
    "# Hyperparameters for set 2\n",
    "learning_rate_2 = 1e-5\n",
    "num_epochs_2 = 1\n",
    "batch_size_2 = 64\n",
    "\n",
    "# Hyperparameters for set 3\n",
    "learning_rate_3 = 2e-5\n",
    "num_epochs_3 = 3\n",
    "batch_size_3 = 16\n",
    "\n",
    "# Train models with different hyperparameters\n",
    "model_1 = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "training_args_1 = TrainingArguments\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
